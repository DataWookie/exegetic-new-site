---
title: "Spark: Big Data from Python"
topic: true
subjects: ['Spark']
draft: false
intro: |
  Apache Spark is a fast, general-purpose system for cluster computing on large datasets.

  This course uses Python to interact with Spark.

  The first part of the course is an introduction to working with Spark. It will enable you to

  - load structured or unstructured data into Spark;
  - understand the way that data are distributed across a Spark cluster;
  - apply transformations and actions to the data.

  In the second part of the course you'll learn how to build Machine Learning models on large datasets using Spark. You'll be able to

  - create classification and regression models;
  - use pipelines to streamline your workflow; and
  - combine pipelines with cross-validation and grid-search to optimise model parameters.

  All material will be available as Jupyter Notebooks.
duration: 2 days
requirements: |
  A working knowledge of Python will be helpful.
---

### Day 1

- Connecting to Spark
- RDDs
	- Unstructured Data
	- Reading data from file
	- Data distribution
	- Transformations
		- Filtering
		- Mapping
	- Actions
	- Persistence
- Key-Value RDDs
	- Creating
	- Transforming
	- Summarising
- Structured Data
	- DataFrames
	- Reading data from file
	- Accessing rows and columns
	- Merging and Aggregation
- Spark SQL
- Partitions
	- How is data partitioned?
	- Repartitioning

### Day 2

- Machine Learning and Big Data
- Working with data
	- Categorical data
		- Indexing
		- One-hot encoding
		- Dense versus Sparse
	- Data preparation
		- Column manipulation
		- Bucketing
		- Assembling columns
	- Text data
		- Punctuation and numbers
		- Tokens
		- Stop words
		- Hashing
		- TF-IDF
- Classification	
	- Decision Tree
	- Logistic Regression
- Regression
	- Linear regression
	- Penalised regression
- Pipelines
- Cross-validation
- Grid search
